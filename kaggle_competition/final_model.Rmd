---
title: "Untitled"
author: "Pascal Schmidt"
date: "November 4, 2019"
output: html_document
---

```{r}
library(tidyverse)
library(imputeTS)
```

### Reading Data

```{r}
# reading in training set
train <- readr::read_csv(here::here("data/train.csv")) %>%

  # create new column with row number
  # important for looking up missing values
  # in the training set that are in the test set
  dplyr::mutate(ID = dplyr::row_number()) %>%

  # some values have abnormally large values. Hence,
  # we decided that we are going to impute NA for outliers
  dplyr::mutate_at(vars(WINDDIR, WINDSPEED, TEMPERATURE, DEWPOINT, PRESSURE),
    .funs = ~ base::ifelse((. > 4 | . < -4), NA, .)
  )

# reading in testing set
test <- readr::read_csv(here::here("data/test.csv"))
head(test)
```

### Linear Interpolation (maxgap = 5)

```{r}
# interpolation beats any model for small gaps of NA values
# therefore, we are imputing values by interpolation for a gap of 3 or smaller
train %>%
  dplyr::mutate_at(vars(WINDDIR, WINDSPEED, TEMPERATURE, DEWPOINT, PRESSURE),
    .funs = ~ imputeTS::na_interpolation(., maxgap = 5)
  ) -> train
head(train)
```

### Building the Test Set

```{r}
test %>%
  tidyr::separate(col = ID, into = c("row", "col"), sep = "-") %>%
  dplyr::mutate_all(.funs = as.numeric) %>%
  dplyr::mutate(column = dplyr::case_when(
    col == 1 ~ "WINDDIR",
    col == 2 ~ "WINDSPEED",
    col == 3 ~ "TEMPERATURE",
    col == 4 ~ "DEWPOINT",
    col == 5 ~ "PRESSURE"
  )) -> to_be_predicted

to_be_predicted %>%
  dplyr::mutate(value = NA) -> to_be_predicted
head(to_be_predicted)

# fill out missing values in df to_be_predicted
# by the interpolated values in the training data set
for (i in 1:nrow(to_be_predicted)) {
  to_be_predicted$value[i] <- train[to_be_predicted$row[i], to_be_predicted$column[i]] %>%
    dplyr::pull()
}

# missing values left
sum(is.na(to_be_predicted$value))

# breakdown of missing values
to_be_predicted %>%
  dplyr::filter(is.na(value)) %>%
  dplyr::pull(column) %>%
  table() 
```

- After having imputed missing values by linear interpolation for a maximum number of three consecutive NA values, we end up with 3461 missing values left to predict.

### Counting Missing Gaps

```{r}
df <- to_be_predicted %>%
  dplyr::filter(is.na(value)) %>%
  dplyr::mutate(
    above = NA,
    below = NA
  )


### Functions Implemented in C++ to reduce run time by about 10min compared to R loops
Rcpp::sourceCpp(here::here("scripts/missing_gap.cpp"))

# count how many missing values there are above and below
# each target missing value in the test set
for (i in c("WINDDIR", "TEMPERATURE", "DEWPOINT", "PRESSURE", "WINDSPEED")) {
  missing_below(
    df$row,
    df$column,
    train[, i] %>%
      dplyr::pull(),
    df$below,
    i
  ) -> df$below
}

for (i in c("WINDDIR", "TEMPERATURE", "DEWPOINT", "PRESSURE", "WINDSPEED")) {
  missing_above(
    df$row,
    df$column,
    train[, i] %>%
      dplyr::pull(),
    df$above,
    i
  ) -> df$above
}

head(df)
```

### Modeling (Linear Regression) for Values With Minimum NAs of 6 Above and Below

```{r}
# only do predictions for values where there is at least
# a 6 gap below and above the target missing values
df %>%
  dplyr::filter(is.na(value)) %>%
  dplyr::filter(above > 6 & below > 6) -> df
```

- There are 308 values left for interpolation at the end 


```{r}
###################################
### Fitting ~3000 Linear Models ###
###################################


# keep rows for which regression model failed
error_row <- c()
# keep r squared
r_squared <- c()

# for each target missing values, determine which other predictors in the row
# of the target missing values are missing as well so we can exclude
# these predictors from our regression and that also ensures we choose as many predictors as possible
for (i in 1:nrow(df)) {

  # pull out predictors which are not missing in response variable row
  train[df$row[[i]], ] %>%
    dplyr::select(WINDDIR:PRESSURE, -c(df$column[[i]], which(is.na(.)))) %>%
    names() -> names_pred

  # if all predictors in row are missing use mean imputation
  if (length(names_pred) == 0) {
    train %>%
      dplyr::filter(USAF == train[df$row[[i]], ]$USAF[[1]] &
        MONTH == train[df$row[[i]], ]$MONTH[[1]]) %>%
      {
        mean(.[, df$column[[i]]] %>%
          dplyr::pull(),
        na.rm = TRUE
        )
      } -> df[i, "value"]

    next
  }

  # check if predictors have more than 40% missing values in column
  # if they do, discard that particular predictor
  train %>%
    dplyr::filter(USAF == train$USAF[[df$row[[i]]]]) %>%
    dplyr::select(names_pred) %>%
    dplyr::summarise_all(.funs = ~ (sum(is.na(.)) / length(.))) %>%
    dplyr::distinct() %>%
    tidyr::gather() %>%
    dplyr::filter(value < 0.40) %>%
    dplyr::pull(key) %>%
    paste(collapse = " + ") -> predictor_vars


  # if there are no predictor_vars because there are more then 40%
  # of missing values in each predictor column, then just impute the
  # average of the response column by station
  if (predictor_vars == "") {
    train %>%
      dplyr::filter(USAF == train[df$row[[i]], ]$USAF[[1]] &
        MONTH == train[df$row[[i]], ]$MONTH[[1]]) %>%
      {
        mean(.[, df$column[[i]]] %>%
          dplyr::pull(),
        na.rm = TRUE
        )
      } -> df[i, "value"]

    next
  }


  # if there are enough observations (500 or more) for a particular station,
  # we do a linear regression by station
  if (train %>%
    dplyr::select(c(USAF, df$column[[i]], stringr::str_split(predictor_vars, pattern = "\\+") %>%
      unlist() %>%
      stringi::stri_trim_both())) %>%
    dplyr::filter(USAF == train$USAF[[df$row[[i]]]]) %>%
    na.omit() %>%
    nrow() > 500) {

    # linear regression formula
    formula <- paste0(df$column[[i]], " ~ MONTH + ", predictor_vars)
    formula <- as.formula(formula)

    # linear model
    lm(formula,
      data = train %>%
        dplyr::filter(USAF == train$USAF[[df$row[[i]]]])
    ) -> lm_model

    # try catch statement when factor MONTH in predict row does not appear in training data
    tryCatch(
      expr = {
        predicted_value <- predict(lm_model, newdata = train[df$row[[i]], ])
        df[i, "value"] <- predicted_value
      },
      error = function(error) {
        error_row <<- c(error_row, i)
        df[i, "value"] <<- NA
        message(paste("Caught an error in row", i))
      }
    )
  }

  # if there are not enough observations for a particular station,
  # we use the entire training data set with the station as a predictor
  else {
    formula <- paste0(df$column[[i]], " ~ MONTH + as.factor(USAF) + ", predictor_vars)
    formula <- as.formula(formula)

    lm(formula,
      data = train
    ) -> lm_model

    # try catch statement when factor MONTH in predict row does not appear in training data
    tryCatch(
      expr = {
        predicted_value <- predict(lm_model, newdata = train[df$row[[i]], ])
        df[i, "value"] <- predicted_value
      },
      error = function(error) {
        error_row <<- c(error_row, i)
        df[i, "value"] <<- NA
        message(paste("Caught an error in row", i))
      }
    )
  }

  # safe r squared in case we want to deal with missing values for
  # low r squared models sepeartely
  r_squared[[i]] <- summary(lm_model)$r.squared
  names(r_squared) <- i
}
```

### Fitting a Linear Regression Model for Temperature and Dewpoint Where the Previous Model Failed

```{r}
df[error_row, ] %>%
  dplyr::filter(column == "DEWPOINT" | column == "TEMPERATURE") -> temp_dew_df


r <- c()
for (i in 1:nrow(temp_dew_df)) {
  if (temp_dew_df$column[[i]] == "TEMPERATURE") {
    lm(TEMPERATURE ~ DEWPOINT + as.factor(MONTH),
      data = train %>%
        dplyr::filter(USAF == train[temp_dew_df$row[[i]], ]$USAF)
    ) -> lm_model
    predicted_value <- predict(lm_model, newdata = train[temp_dew_df$row[[i]], ])
    temp_dew_df[i, "value"] <- predicted_value
    r[[i]] <- summary(lm_model)$r.squared
  } else {
    lm(DEWPOINT ~ TEMPERATURE + as.factor(MONTH),
      data = train %>%
        dplyr::filter(USAF == train[temp_dew_df$row[[i]], ]$USAF)
    ) -> lm_model
    predicted_value <- predict(lm_model, newdata = train[temp_dew_df$row[[i]], ])
    temp_dew_df[i, "value"] <- predicted_value
    r[[i]] <- summary(lm_model)$r.squared
  }
}

# join imputed values with test data set
df %>%
  tidyr::unite(together, c("row", "column")) %>%
  dplyr::left_join(temp_dew_df %>%
    tidyr::unite(together, c("row", "column")) %>%
    select(together, value), by = "together") %>%
  dplyr::mutate(value.x = ifelse(!(is.na(value.y)), value.y, value.x)) %>%
  dplyr::rename(value = value.x) %>%
  tidyr::separate(together, into = c("row", "column"), remove = FALSE) %>%
  dplyr::select(-c(value.y, together)) -> df
```

```{r}
to_be_predicted %>%
  tidyr::unite(together, c("row", "column")) %>%
  dplyr::left_join(df %>%
    tidyr::unite(together, c("row", "column")) %>%
    select(together, value), by = "together") %>%
  dplyr::mutate(value.x = ifelse(!(is.na(value.y)), value.y, value.x)) %>%
  dplyr::rename(value = value.x) %>%
  tidyr::separate(together, into = c("row", "column"), remove = FALSE) %>%
  dplyr::select(-c(value.y, together)) -> to_be_predicted

# interpolation for rest of missing NAs
train %>%
  dplyr::mutate_at(vars(WINDDIR, WINDSPEED, TEMPERATURE, DEWPOINT, PRESSURE),
    .funs = ~ imputeTS::na_interpolation(.)
  ) -> train

for (i in 1:nrow(to_be_predicted)) {
  if (is.na(to_be_predicted$value[[i]])) {
    to_be_predicted[i, "value"] <- train[to_be_predicted$row[i], to_be_predicted$column[i]] %>%
      dplyr::pull()
  }
}

to_be_predicted %>%
  dplyr::rename(ID = row, Value = value) %>%
  tidyr::unite(col = ID, ID, col, sep = "-", remove = FALSE) %>%
  dplyr::select(-column, -col) -> predicted_values

readr::write_csv(predicted_values, "predictions/interpolation_lm.csv")
```

